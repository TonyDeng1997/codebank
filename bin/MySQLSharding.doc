SQL Sharding

Sharding: MySQL sharding os useful when there is large no of write operations 
in a high traffic website. By sharding MySQL servers, the application is partitioned 
into multiple servers dividing the database into small chunks. As low cost servers can 
be deployed for this purpose, this is cost effective.

The figure below depicts the difference in the initial setup between using and not using MySQL Fabric.






The employee, department and the salary tables are sharded based on the emp_no that is used as the shard key.

The fuel_reimb represents a table that is often used (in joins queries) to find the fuel allowance for various employees. All the data in this table is often required in joins.

Starting MySQL Fabric
1.Configure the fabric.cfg for configuring Fabric, to use this MySQL server as the state store.
2.Fabric persists metadata about the shard topology in a set of relation tables in the MySQL Server acting as the state store. This step creates the schemas of the tables in the state store.
mysqlfabric manage setup

3.Starting the fabric server

Mysqlfabric manage start
4. ?Creating the sharding topology
The global group in a sharding setup is used to propagate schema updates to all tables in the sharding setup and updates to global tables throughout the sharding ecosystem. The global group contains,

?The schema of the sharded tables
?The global tables

Commands:

mysqlfabric group create GLOBAL_GROUP
mysqlfabric group add GLOBAL_GROUP localhost:13001 root ""

mysqlfabric group add GLOBAL_GROUP localhost:13002 root ""

Find the UUID of localhost:13001 and promote it as master

mysqlfabric group lookup_servers GLOBAL_GROUP

mysqlfabric group promote GLOBAL_GROUP <UUID of MySQL Server running on localhost:13001>



Creating the Server Group (for the first shard)
Each shard maps to a server group. Each server group is a set of MySQL servers in a HA configuration. The application starts with a single server group and adds more shards (server groups) as required. Let us create the first shard.

Each shard maps to a server group. Each server group is a set of MySQL servers in a HA configuration. The application starts with a single server group and adds more shards (server groups) as required. Let us create the first shard.

Commands:

mysqlfabric group create GROUPID1

mysqlfabric group add GROUPID1 localhost:13003 root ""

mysqlfabric group add GROUPID1 localhost:13004 root ""

mysqlfabric group lookup_servers GROUPID1

mysqlfabric group promote <UUID of MySQLServer running on localhost:13003>



Now it looks like this,




Create a Sharding Definition
A sharding definition introduces a particular sharding scheme to which multiple tables (related by a common sharding key) can be mapped. A Sharding definition is composed of

?Sharding scheme 每 RANGE, HASH
?Global Group 每 Gets the global updates for all the shard tables mapped to this sharding definition. It also stores the global tables in this sharding definition.

Command

mysqlfabric sharding define RANGE GLOBAL_GROUP

Map the tables to the sharding definition
Each sharding definition is associated with a unique ID. This unique ID is generated when we create a sharding definition. In the above case this ID is 1.We map this unique ID to the table being sharded. Each mapping maps a table and the column containing the shard key to the sharding definition.

Commands:
mysqlfabric sharding add_mapping 1 employee.employee emp_no
mysqlfabric sharding add_mapping 1 employee.salaries emp_no
mysqlfabric sharding add_mapping 1 employee.dept_emp emp_no


Add the Shards
When we add shards we define the way the data is sharded based on the shard key. Each of the shards,
?Specify the shard mapping ID to which it belongs.
?It also specifies the group in which the shard data will be present.
?When we add a shard we also need to specify if it will be ENABLED for operations on shards.
?A RANGE shard definition also specifies a lower_bound which represents the least value of the shard key that will be present in a particular shard. In this case we assume that the lower_bound=1. 

Commands:

mysqlfabric sharding add_shard 1 GROUPID1 ENABLED 1



So far, the global group has two instances of mysql, and groupId1 has two instances of mysql.


Define the Schema on the Global Group
The schema for the tables is defined on the master of the global group so that it gets replicated to all the shards. That is to say, mysql connects to the master node of the global group, and create db schemas.


Queries:

CREATE DATABASE employee;

use employee;

CREATE TABLE employee(emp_no INT PRIMARY KEY AUTO_INCREMENT, birth_date DATE, first_name VARCHAR(14), last_name VARCHAR(16), gender ENUM('M','F'), hire_date DATE);

CREATE TABLE salaries(emp_no INT, salary INT, from_date DATE, to_date DATE, FOREIGN KEY(emp_no) REFERENCES employee(emp_no));

CREATE TABLE dept_emp(emp_no INT, dept_no CHAR(4), from_date DATE, to_date DATE, FOREIGN KEY(emp_no) REFERENCES employee(emp_no));

CREATE TABLE fuel_reimb(role VARCHAR(20), allowance INTEGER);


Write the Application
The below application is written in Python. The application is very simple and uses connector python to insert a row into the table. The goal of the application is to demonstrate the extensions in the python connector that make it FABRIC aware.



Application Code:

import mysql.connector.fabric as connector

if __name__ == "__main__":

fabric_params = {

"fabric" : {"host" : "localhost", "port" : 8080},

"user" : "root", "passwd" : ""

}

__cnx = connector.MySQLFabricConnection(**fabric_params)

__cnx.set_property(key=str(1),tables=["employee.employee"])

cur = __cnx.cursor()

cur.execute("use employee")

cur.execute("INSERT INTO employee(birth_date, first_name, last_name, gender, hire_date) VALUES(NULL, 'A', 'B', 'M', NULL)")

__cnx.commit()

?Explanation:

fabric_params = {

"fabric" : {"host" : "localhost", "port" : 8080},

"user" : "root", "passwd" : ""

}

__cnx = connector.MySQLFabricConnection(**fabric_params)

The above code gets a connection to the running Fabric XML-RPC server. The parameters that are passed to the MySQLFabricConnection class are

※host§ - The hostname at which the Fabric server runs.

※port§ - The port number at which the Fabric server runs.

※user§, ※passwd§ - Login credentials for the Fabric state store.

__cnx.set_property(key=str(1),tables=["employee.employee"])

key 每 The shard key value

tables 每 The table name being sharded.

set_property automatically redirects internally to the correct shard on which the queries are executed.

If a query needs to be executed on all the shards, example an update on a global table or a schema change operation on all the shards, then add a parameter

scope = ※GLOBAL§

to signify global operations. This is set of ※LOCAL§ by default.

Questions: execute query on all the shards


Adding more Shards
As the size of the shard increases, we add more shards to the sharding topology.







Commands:

Add a group for the shard

mysqlfabric group create GROUPID2
mysqlfabric group add GROUPID2 localhost:13005 root ""

mysqlfabric group add GROUPID2 localhost:13006 root ""
mysqlfabric group lookup_servers GROUPID2

mysqlfabric group promote <UUID of MySQLServer running on localhost:13005>

Add the shard definition

The difference from the previous definition will be that the lower_bound will point to employee number from which we start inserting into this shard. In this case we choose a hypothetical value of 10001. This means that starting 10001 the employee information will be stored in this shard.

mysqlfabric sharding add_shard 1 GROUPID2 ENABLED 10001

The following will direct the application to this new shard.

__cnx.set_property(key=str(10001),tables=["employee.employee"])

In the above case any key value greater than 10001 will automatically redirect the insert to the new shard.

NOTE: The above step actually adds a new shard starting at a specified lower_bound. Other options for moving data around in a sharded setup are shard moves and splits. These shall be explored in later blogs.

Ref:
http://vnwrites.blogspot.com/2013/09/mysqlfabric-sharding-example.html


What and why

Sharding is the process of splitting up your data so it resides in different tables or often different physical databases.

Logical Shards

First when initially implementing sharding you＊ll want to create an arbitrary number of logical shards. This will allow you to change less code later when it comes to adding more shards. You＊ll also want to define your shards to the power of 2. Generally I＊d recommend for most services 1024 can be a good number, I believe Instagram actually used 4096, either can really be an appropriate number.

A table looks like this,

 id |           email           |      name       
----+---------------------------+-----------------
  1 | craig.kerstiens@gmail.com | Craig Kerstiens
  2 | john.doe@gmail.com        | John Doe
  3 | jane.doe@gmail.com        | Jane Doe
  4 | user4@gmail.com           | User 4
  5 | user5@gmail.com           | User 5
  6 | user6@gmail.com           | User 6
  7 | user7@gmail.com           | User 7
  8 | user8@gmail.com           | User 8

Let us divide it into 4 logic shards.


Now, if id is auto increment, then we could use some sort of hash, like hash of email to as shard key. To decide a shard, logical_shard = hash(User.email) % 4

Question, when we create the shard mapping like the below, we can replace emp_no with User.email.

mysqlfabric sharding add_mapping 1 employee.employee hash(employee.email)%4

Physical Shards
From here we＊ll then take the logical shards and create actual physical shards. If you have a single physical shard you＊re using a single database, but the rest of your application code is ready to handle additional shards. For now lets use an example of two physical shards, the end result would be dividing our data up somehow like this:


The physical shard to access can easily be counted by taking the modulus of the logical shard its on by the physical shards that exist:

total_physical_shards = 2
total_logical_shards = 4
logical_shard = hash(User.email) % total_logical_shards
physical_shard = logical_shard % total_physical_shards




Generating IDs (Primary Keys)
As you＊re distributing data across multiple databases you＊ll want to avoid using an integer as your primary key. This would cause for keys to be duplicated within your database and make for a headache when attempting to report against your data. Instead the ideal is to use a UUID as the primary key. By using a UUID and generating this in either your application code or within your database you ensure each User ID is actually unique. Note: UUID is a string and Auto generated id will repeat in different db.
Adding Capacity
The best case scenario for most web applications, such is the case for Instagram, is to have to scale beyond their initial capacity, in order to do this you＊ll simple expand the number of physical shards. In order to do this you＊ll want to move data from one physical shard to another, then remove data from the old physical shard. Its also generally a good practice to grow your physical shards in powers of 2 the same way you would your logical shards. Lets take a look at a clearer example of how we would do this using the Heroku Postgres Service＃

Questions: 

What is the physical shard? Is it an instance of MySQL server?


What is the logic shard? It is an table sitting in different db but in the same MySQL server?

First we＊re going to add a follower for each shard we have:




We＊re then going to promote our followers to be their own independent databases which can accept writes. This means we＊ll have two copies that can be written to with the same data:



At this point you can update your application code to have the new number of physical shards and it should begin writing data to the appropriate place. Of course you do still want to clean up some of that extra data. To do this you＊ll want to remove the data that doesn＊t belong in the appropriate shard. For example, id of 3 wouldn＊t belong in physical shard 1 any more. Now we can run a background process to clean up such data:



Ref: http://www.craigkerstiens.com/2012/11/30/sharding-your-database/
Sharding
Each shard is held on a separate database server instance, to spread load.

Horizontal partitioning 
Horizontal partitioning is a database design principle whereby rows of a database table are held separately, rather than being split into columns (which is what normalization and vertical partitioning do, to differing extents). Each partition forms part of a shard, which may in turn be located on a separate database server or physical location.

Sharding vs Horizontal partitioning in one db
Splitting shards across multiple isolated instances requires more than simple horizontal partitioning. The hoped-for gains in efficiency would be lost, if querying the database required both instances to be queried, just to retrieve a simple dimension table. Beyond partitioning, sharding thus splits large partitionable tables across the servers, while smaller tables are replicated as complete units.

Ref:
https://en.wikipedia.org/wiki/Shard_(database_architecture)